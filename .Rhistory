## Compute the Auto-covariance
auto.cov<-apply(d.mat,2, function(x) acf(x, "covariance")$acf)
auto.cov<-auto.cov[-1,]
auto.cov<-rbind(gamma0,auto.cov)
##Compute the Kernel matrix Politis and Romano 1994
i<-as.matrix(seq(1,nrow(d.mat)-1))
kernel <- c(0,apply(i,1,function(x) ((n-x)/n)*((1-bandwidth)^x)+(x/n)*((1-bandwidth)^(n-x))))
##Compute a consistent estimator
omega <-apply(auto.cov,2,function(x) x*kernel)
help(acf)
auto.cov<-apply(d.mat,2, function(x) acf(x, "covariance", plot = F)$acf)
auto.cov<-auto.cov[-1,]
auto.cov<-rbind(gamma0,auto.cov)
i<-as.matrix(seq(1,nrow(d.mat)-1))
kernel <- c(0,apply(i,1,function(x) ((n-x)/n)*((1-bandwidth)^x)+(x/n)*((1-bandwidth)^(n-x))))
omega <-apply(auto.cov,2,function(x) x*kernel)
colSums(omega)*2
omega <- auto.cov[1,]+colSums(omega)*2
# Computes the T.spa Statistic
t.SPA <- max(max(sqrt(n)*d.bar/omega),0)
#Apply the Hansen function
if(typeFunc==0){
gFunc <- apply(as.matrix(d.bar),1,function(x) max(x,0))
}else if(typeFunc==1){
gFunc <- apply(as.matrix(d.bar),1,function(x) x*ifelse(x>=-sqrt(((omega^2)/n)*log(log(n))),1,0))
}else{
gFunc <- d.bar
}
Z <- t(apply(d.mat,1,function(x) x - gFunc))
#Stationary Bootstrap
Zboot <- boot::tsboot(Z,statistic=colMeans, R=B,l=geomMean,sim="geom")$t*sqrt(n)
library(mlRFinance)
#Step 0: Computes the performance of model k relative to the benchmark at time t.
d.mat <- apply(Dmat,2,function(x)x-bVec)
#Size of the Time series
n<-length(bVec)
#Step 1: Compute d.bar
d.bar  <- colMeans(d.mat)
#Find a consistent estimator of V(n^(1/2)*overline(d)_{k})
##Computes the variance
gamma0 <- sqrt(apply(d.mat,2,var))
## Compute the Auto-covariance
auto.cov<-apply(d.mat,2, function(x) acf(x, "covariance", plot = F)$acf)
auto.cov<-auto.cov[-1,]
auto.cov<-rbind(gamma0,auto.cov)
##Compute the Kernel matrix Politis and Romano 1994
i<-as.matrix(seq(1,nrow(d.mat)-1))
kernel <- c(0,apply(i,1,function(x) ((n-x)/n)*((1-bandwidth)^x)+(x/n)*((1-bandwidth)^(n-x))))
##Compute a consistent estimator
omega <-apply(auto.cov,2,function(x) x*kernel)
omega <- auto.cov[1,]+colSums(omega)*2
# Computes the T.spa Statistic
t.SPA <- max(max(sqrt(n)*d.bar/omega),0)
#Apply the Hansen function
if(typeFunc==0){
gFunc <- apply(as.matrix(d.bar),1,function(x) max(x,0))
}else if(typeFunc==1){
gFunc <- apply(as.matrix(d.bar),1,function(x) x*ifelse(x>=-sqrt(((omega^2)/n)*log(log(n))),1,0))
}else{
gFunc <- d.bar
}
Z <- t(apply(d.mat,1,function(x) x - gFunc))
#Stationary Bootstrap
Zboot <- boot::tsboot(Z,statistic=colMeans, R=B,l=geomMean,sim="geom")$t*sqrt(n)
#Boostrap T.SPA
T.SPA <- t(apply(Zboot,1,function(x) x/omega))
#For each time series:
T.SPA <- apply(as.matrix(apply(T.SPA,1,max)),1,function(x) max(x,0))
#P-value
p.value <- mean(T.SPA>t.SPA)
typeFunc<-2
#Step 0: Computes the performance of model k relative to the benchmark at time t.
d.mat <- apply(Dmat,2,function(x)x-bVec)
#Size of the Time series
n<-length(bVec)
#Step 1: Compute d.bar
d.bar  <- colMeans(d.mat)
#Find a consistent estimator of V(n^(1/2)*overline(d)_{k})
##Computes the variance
gamma0 <- sqrt(apply(d.mat,2,var))
## Compute the Auto-covariance
auto.cov<-apply(d.mat,2, function(x) acf(x, "covariance", plot = F)$acf)
auto.cov<-auto.cov[-1,]
auto.cov<-rbind(gamma0,auto.cov)
##Compute the Kernel matrix Politis and Romano 1994
i<-as.matrix(seq(1,nrow(d.mat)-1))
kernel <- c(0,apply(i,1,function(x) ((n-x)/n)*((1-bandwidth)^x)+(x/n)*((1-bandwidth)^(n-x))))
##Compute a consistent estimator
omega <-apply(auto.cov,2,function(x) x*kernel)
omega <- auto.cov[1,]+colSums(omega)*2
# Computes the T.spa Statistic
t.SPA <- max(max(sqrt(n)*d.bar/omega),0)
gFunc <- apply(as.matrix(d.bar),1,function(x) x*ifelse(x>=-sqrt(((omega^2)/n)*log(log(n))),1,0))
Z <- t(apply(d.mat,1,function(x) x - gFunc))
Zboot <- boot::tsboot(Z,statistic=colMeans, R=B,l=geomMean,sim="geom")$t*sqrt(n)
B<-1000
Zboot <- boot::tsboot(Z,statistic=colMeans, R=B,l=geomMean,sim="geom")$t*sqrt(n)
help(tsboot)
geomMean<-20
Zboot <- boot::tsboot(Z,statistic=colMeans, R=B,l=geomMean,sim="geom")$t*sqrt(n)
T.SPA <- t(apply(Zboot,1,function(x) x/omega))
T.SPA <- apply(as.matrix(apply(T.SPA,1,max)),1,function(x) max(x,0))
T.SPABoot <- t(apply(Zboot,1,function(x) x/omega))
B
# Specify the model parameters
m_null = 3
m_alt = 7
m = m_null + m_alt
mu = c( rep(0, m_null), rep(0.5,m_alt) )
rho = 0.25
omega= (1-rho)*diag(1,m) + rho*matrix(1,m,m)
v=t(chol(omega))
# generate the data
n = 100
y = mu%*%matrix(1,1,n)+ v %*% matrix(rnorm(m*n),m,n)
# calculate the test statistics and bootstrap statistics
library(foreach)
library(tseries)
install.packages("tseries")
# Specify the model parameters
m_null = 3
m_alt = 7
m = m_null + m_alt
mu = c( rep(0, m_null), rep(0.5,m_alt) )
rho = 0.25
omega= (1-rho)*diag(1,m) + rho*matrix(1,m,m)
v=t(chol(omega))
# generate the data
n = 100
y = mu%*%matrix(1,1,n)+ v %*% matrix(rnorm(m*n),m,n)
# calculate the test statistics and bootstrap statistics
library(foreach)
library(tseries)
B = 100
y_mean = apply(y,1,mean)
y_sig = apply(y,1,sd)
t_stat = as.matrix(sqrt(n)*y_mean/y_sig)
s = tsbootstrap(1:n,B,b=2,type="stationary")
b_stat = foreach(i=1:B,.combine=cbind) %do% {
y_boot = y[, s[,i]]
y_mean_boot = apply(y_boot,1,mean)
sqrt(n)*(y_mean_boot - y_mean)/y_sig
}
B
n
# Specify the model parameters
m_null = 3
m_alt = 7
m = m_null + m_alt
mu = c( rep(0, m_null), rep(0.5,m_alt) )
rho = 0.25
omega= (1-rho)*diag(1,m) + rho*matrix(1,m,m)
v=t(chol(omega))
# generate the data
n = 1000
y = mu%*%matrix(1,1,n)+ v %*% matrix(rnorm(m*n),m,n)
# calculate the test statistics and bootstrap statistics
library(foreach)
library(tseries)
B = 100
y_mean = apply(y,1,mean)
y_sig = apply(y,1,sd)
t_stat = as.matrix(sqrt(n)*y_mean/y_sig)
s = tsbootstrap(1:n,B,b=2,type="stationary")
help(tsboot)
T.SPABoot <- t(apply(Zboot,1,function(x) x/omega))
gFunc <- apply(as.matrix(d.bar),1,function(x) x*ifelse(x>=-sqrt(((omega^2)/n)*log(log(n))),1,0))
View(gFunc)
View(gFunc)
d.bar
gFunc <- apply(as.matrix(d.bar),1,function(x) max(x,0))
gFunc
gFunc <- apply(as.matrix(d.bar),1,function(x) x*ifelse(x>=-sqrt(((omega^2)/n)*log(log(n))),1,0))
omega
#Step 0: Computes the performance of model k relative to the benchmark at time t.
d.mat <- apply(Dmat,2,function(x)x-bVec)
#Size of the Time series
n<-length(bVec)
#Step 1: Compute d.bar
d.bar  <- colMeans(d.mat)
##White works with a non standardized statistic
omega <-rep(1,ncol(Dmat))
# Computes the T.spa Statistic
t.SPA <- max(max(sqrt(n)*d.bar/omega),0)
bVec<-runif(1000,0,1)
#Step 0: Computes the performance of model k relative to the benchmark at time t.
d.mat <- apply(Dmat,2,function(x)x-bVec)
#Size of the Time series
n<-length(bVec)
#Step 1: Compute d.bar
d.bar  <- colMeans(d.mat)
##White works with a non standardized statistic
omega <-rep(1,ncol(Dmat))
Dmat<-matric(runif(10000,0,1),ncol=10,nrow=1000)
Dmat<-matrix(runif(10000,0,1),ncol=10,nrow=1000)
#Step 0: Computes the performance of model k relative to the benchmark at time t.
d.mat <- apply(Dmat,2,function(x)x-bVec)
#Size of the Time series
n<-length(bVec)
#Step 1: Compute d.bar
d.bar  <- colMeans(d.mat)
##White works with a non standardized statistic
omega <-rep(1,ncol(Dmat))
t.SPA <- max(max(sqrt(n)*d.bar/omega),0)
t.SPA
gFunc <- apply(as.matrix(d.bar),1,function(x) max(x,0))
gFunc
gFunc <- apply(as.matrix(d.bar),1,function(x) x*ifelse(x>=-sqrt(((omega^2)/n)*log(log(n))),1,0))
gFunc
gFunc <- rep(NA,length(d.bar) )
for(i in 1:length(d.bar)){
gFunc[i] <- d.bar[i]*ifelse(d.bar[i]>=-sqrt(((omega[i]^2)/n)*log(log(n))),1,0)
}
gFunc
gFunc <- d.bar
gFunc
gFunc <- rep(NA,length(d.bar) )
for(i in 1:length(d.bar)){
gFunc[i] <- d.bar[i]*ifelse(d.bar[i]>=-sqrt(((omega[i]^2)/n)*log(log(n))),1,0)
}
Z <- t(apply(d.mat,1,function(x) x - gFunc))
Zboot <- boot::tsboot(Z,statistic=colMeans, R=B,l=geomMean,sim="geom")$t*sqrt(n)
T.SPABoot <- t(apply(Zboot,1,function(x) x/omega))
B
T.SPA <- apply(as.matrix(apply(T.SPABoot,1,max)),1,function(x) max(x,0))
p.value <- mean(T.SPA>t.SPA)
p.value
fdp <- FDPControl(t.SPA, t(T.SPABoot), gamma, alpha)
alpha<-0.05
gamma<-0.1
fdp <- FDPControl(t.SPA, t(T.SPABoot), gamma, alpha)
#Generate the sample
Dmat<-matrix(runif(10000,ncol=10,nrow=1000),nrow=1000,ncol=10)
bvec<-runif(1000)
typeFunc<-1
B<-500
geomMean<-20
bandwidth<-0.5
alpha<-0.05
k<-1
gamma<-0.1
#Step 0: Computes the performance of model k relative to the benchmark at time t.
d.mat <- apply(Dmat,2,function(x)x-bVec)
#Size of the Time series
n<-length(bVec)
#Step 1: Compute d.bar
d.bar  <- colMeans(d.mat)
#Find a consistent estimator of V(n^(1/2)*overline(d)_{k})
##Computes the variance
gamma0 <- sqrt(apply(d.mat,2,var))
## Compute the Auto-covariance
auto.cov<-apply(d.mat,2, function(x) acf(x, "covariance", plot = F)$acf)
auto.cov<-auto.cov[-1,]
auto.cov<-rbind(gamma0,auto.cov)
##Compute the Kernel matrix Politis and Romano 1994
i<-as.matrix(seq(1,nrow(d.mat)-1))
kernel <- c(0,apply(i,1,function(x) ((n-x)/n)*((1-bandwidth)^x)+(x/n)*((1-bandwidth)^(n-x))))
##Compute a consistent estimator
omega <-apply(auto.cov,2,function(x) x*kernel)
omega <- auto.cov[1,]+colSums(omega)*2
# Computes the T.spa Statistic
t.SPA <- max(max(sqrt(n)*d.bar/omega),0)
#Apply the Hansen function
if(typeFunc==0){
gFunc <- apply(as.matrix(d.bar),1,function(x) max(x,0))
}else if(typeFunc==1){
gFunc <- rep(NA,length(d.bar) )
for(i in 1:length(d.bar)){
gFunc[i] <- d.bar[i]*ifelse(d.bar[i]>=-sqrt(((omega[i]^2)/n)*log(log(n))),1,0)
}
}else{
gFunc <- d.bar
}
Z <- t(apply(d.mat,1,function(x) x - gFunc))
Zboot <- boot::tsboot(Z,statistic=colMeans, R=B,l=geomMean,sim="geom")$t*sqrt(n)
T.SPABoot <- t(apply(Zboot,1,function(x) x/omega))
T.SPA <- apply(as.matrix(apply(T.SPABoot,1,max)),1,function(x) max(x,0))
p.value <- mean(T.SPA>t.SPA)
fdp <- FDPControl(t.SPA, t(T.SPABoot), gamma, alpha)
fwer <- FWERkControl(t.SPA, t(T.SPABoot), k, alpha)
library(mlRFinance)
tt<-hansen.spa(Dmat,bVec,typeFunc=1,B=1000,geomMean=20,bandwidth=0.5, alpha=0.05, k=1, gamma=0.1)
fdp<-tt$FDP
fdp
fdp<-tt$FWERk
fdp
tt
library(mlRFinance)
library(mlRFinance)
help(acf)
help(tsboot)
library(mlRFinance)
library(mlRFinance)
library(mlRFinance)
library(mlRFinance)
library(mlRFinance)
library(mlRFinance)
install.packages("RSelenium")
library(RSelenium)
checkForServer()
checkForServer()
RSelenium::startServer()
#Instalação do RSelenium
library(RSelenium)
#Confere se o RSelenium está instalado
#checkForServer()
RSelenium::startServer()
remDr <- remoteDriver(browserName = "phantomjs")
remDr$open()
remDr$maxWindowSize()
#Instalação do RSelenium
library(RSelenium)
#Confere se o RSelenium está instalado
#checkForServer()
RSelenium::startServer()
suppressMessages(RSelenium::startServer())
remDr <- remoteDriver(browserName = "phantomjs")
remDr$open()
remDr$close()
remDr$closeServer()
remDr$close()
remDr$closeServer()
RSelenium::startServer(log = FALSE, invisible = FALSE)
RSelenium::startServer(log = FALSE, invisible = TRUE)
remDr <- remoteDriver(browserName = "phantomjs")
RSelenium::startServer(log = FALSE, invisible = TRUE)
remDr$open(silent = TRUE)
remDr$maxWindowSize()
RSelenium::checkForServer()
#Fecha as conexões
remDr$close()
remDr$closeServer()
RSelenium::checkForServer()
RSelenium::startServer()
library(RSelenium)
startServer()
# remDr <- remoteDriver(browserName = "chrome")
remDr <- remoteDriver()
remDr$open()
remDr$navigate("http://www.r-project.org")  # Works
#Instala o Servidor:
RSelenium::checkForServer()
#Inicia o servidor
RSelenium::startServer()
require(RSelenium)
remDr <- remoteDriver(remoteServerAddr = "localhost"
, port = 4444
, browserName = "firefox"
)
remDr$open()
library(RSelenium)
checkForServer()
startServer()
remDr <- remoteDriver()
remDr$open()
remDr$navigate("http://www.google.com/ncr")
library(RSelenium)
checkForServer()
startServer()
remDr <- remoteDriver()
remDr$open()
remDr$navigate("http://www.google.com/ncr")
library(RSelenium)
checkForServer()
startServer()
remDr <- remoteDriver()
remDr$open()
library(RSelenium)
checkForServer()
startServer()
remDr <- remoteDriver()
remDr$open()
C<-seq(1,10)
parmMat<-matrix(c(1,2,))
parmMat<-matrix(c(1,2,3,4,5,6),ncol=2,nrow=3)
parmMat
matAll<-merge(C,parmMat)
View(matAll)
colnames(matAll)<-c("C", paste0("Parm",seq(0,ncol(parmMat)-1)))
View(parmMat)
View(matAll)
i<-1
View(matAll)
parmsM<-as.numeric(matAll[i,2:(ncol(parmMat))])
parmsM<-as.numeric(matAll[i,2:ncol(matAll)])
i<-2
parmsM<-as.numeric(matAll[i,2:ncol(matAll)])
parmsM<-as.numeric(matAll[i,2:ncol(matAll)])
i<-4
parmsM<-as.numeric(matAll[i,2:ncol(matAll)])
library(mlRFinance)
#MlRFinance
rm(list=ls())
library(mlRFinance)
library(quantmod)
#Cria um novo ambiente para armazenar os dados
stockData <- new.env()
#Especifica as datas de interesse
startDate = as.Date("2011-01-01")
endDate = as.Date("2011-12-31")
#Obtêm os dados do ativo PETR4 e PETR3
getSymbols("^BVSP", src="yahoo",from=startDate,to=endDate)
#Calcula o log-retorno
retorno<-na.omit(diff(log(Cl(BVSP))))
#Training set
train <- as.numeric(retorno[1:180])
#Validation set
valid <- as.numeric(retorno[181:216])
#Cost parameter - Mean Equation
Cmean<-seq(0.01,10)
#Epsilon parameter - Mean Equation
epsilonMean <-seq(0.04,0.5,length.out=7)
#Kernel mean equation
kernelMean <- "Gaussian"
#parameters kernel - Mean Equation
parmsMean <-matrix(c(1.0,
1.5,
2.0),ncol=1,nrow=3,byrow=T)
#Cost parameter - Volatility Equation
Cvola <-seq(0.5,0.7,length.out = 4)
#Epsilon parameter - Volatility Equation
epsilonVola <-seq(0.01,0.9,length.out=4)
#Kernel - Volatility Equation
kernelVolat <- "Polynomial"
#parameters kernel - Volatility Equation
parmsVola <- matrix(c(2,1,
1.5,5,
2.0,7),ncol=2,nrow=3,byrow=T)
teste<-GarchSVR(train,valid,Cmean,epsilonMean,kernelMean,parmsMean,
Cvola,epsilonVola,kernelVolat,parmsVola)
#MlRFinance
rm(list=ls())
library(mlRFinance)
library(quantmod)
#Cria um novo ambiente para armazenar os dados
stockData <- new.env()
#Especifica as datas de interesse
startDate = as.Date("2011-01-01")
endDate = as.Date("2011-12-31")
#Obtêm os dados do ativo PETR4 e PETR3
getSymbols("^BVSP", src="yahoo",from=startDate,to=endDate)
#Calcula o log-retorno
retorno<-na.omit(diff(log(Cl(BVSP))))
#Training set
train <- as.numeric(retorno[1:180])
#Validation set
valid <- as.numeric(retorno[181:216])
#Cost parameter - Mean Equation
Cmean<-seq(0.01,10)
#Epsilon parameter - Mean Equation
epsilonMean <-seq(0.04,0.5,length.out=7)
#Kernel mean equation
kernelMean <- "Gaussian"
#parameters kernel - Mean Equation
parmsMean <-matrix(c(1.0,
1.5,
2.0),ncol=1,nrow=3,byrow=T)
#Cost parameter - Volatility Equation
Cvola <-seq(0.5,0.7,length.out = 4)
#Epsilon parameter - Volatility Equation
epsilonVola <-seq(0.01,0.9,length.out=4)
#Kernel - Volatility Equation
kernelVolat <- "Polynomial"
#parameters kernel - Volatility Equation
parmsVola <- matrix(c(2,1,
1.5,5,
2.0,7),ncol=2,nrow=3,byrow=T)
svm<-GARCHCSVRL1(train, valid, Cmean[1], epsilonMean[1], Cvola[1], epsilonVola[1],
kernelMean, parmsMean[1,], kernelVolat, parmsVola[1,])
svm$ErrorMeasureValidation$MSE
svm$ErrorMeasureValidationGarch$MSE
Cmean
#MlRFinance
rm(list=ls())
library(mlRFinance)
library(quantmod)
#Cria um novo ambiente para armazenar os dados
stockData <- new.env()
#Especifica as datas de interesse
startDate = as.Date("2011-01-01")
endDate = as.Date("2011-12-31")
#Obtêm os dados do ativo PETR4 e PETR3
getSymbols("^BVSP", src="yahoo",from=startDate,to=endDate)
#Calcula o log-retorno
retorno<-na.omit(diff(log(Cl(BVSP))))
#Training set
train <- as.numeric(retorno[1:180])
#Validation set
valid <- as.numeric(retorno[181:216])
#Cost parameter - Mean Equation
Cmean<-seq(0.01,0.1,length.out = 5)
#Epsilon parameter - Mean Equation
epsilonMean <-seq(0.04,0.5,length.out=7)
#Kernel mean equation
kernelMean <- "Gaussian"
#parameters kernel - Mean Equation
parmsMean <-matrix(c(1.0,
1.5,
2.0),ncol=1,nrow=3,byrow=T)
#Cost parameter - Volatility Equation
Cvola <-seq(0.5,0.7,length.out = 4)
#Epsilon parameter - Volatility Equation
epsilonVola <-seq(0.01,0.9,length.out=4)
#Kernel - Volatility Equation
kernelVolat <- "Polynomial"
#parameters kernel - Volatility Equation
parmsVola <- matrix(c(2,1,
1.5,5,
2.0,7),ncol=2,nrow=3,byrow=T)
#Do the cross-validation
teste<-GarchSVR(train,valid,Cmean,epsilonMean,kernelMean,parmsMean,
Cvola,epsilonVola,kernelVolat,parmsVola)
